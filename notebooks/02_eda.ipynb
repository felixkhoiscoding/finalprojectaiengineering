{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 2: Exploratory Data Analysis (EDA)\n",
                "\n",
                "**Objective:** Analyze time series patterns, trends, seasonality, and statistical properties\n",
                "\n",
                "**Focus Areas:**\n",
                "- Time series visualization\n",
                "- Trend and seasonality decomposition\n",
                "- Stationarity testing\n",
                "- Autocorrelation analysis (ACF/PACF)\n",
                "- Distribution and outlier detection\n",
                "- Temporal patterns (MoM, YoY changes)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.1 Setup and Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import sys\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Statistical libraries\n",
                "from statsmodels.tsa.seasonal import seasonal_decompose\n",
                "from statsmodels.tsa.stattools import adfuller, kpss\n",
                "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
                "from scipy import stats\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path.cwd().parent\n",
                "sys.path.append(str(project_root))\n",
                "\n",
                "# Import custom modules\n",
                "from src.data_loader import load_data\n",
                "from src import visualization as viz\n",
                "from config.config import RAW_DATA_PATH, FIGURES_DIR\n",
                "\n",
                "# Ensure figures directory exists\n",
                "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Display settings\n",
                "pd.set_option('display.max_columns', None)\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print(\"[OK] All imports successful!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "df = load_data(filepath=RAW_DATA_PATH, sheet_name='Monthly')\n",
                "print(f\"\\nDataset loaded: {len(df)} observations\")\n",
                "print(f\"Date range: {df['observation_date'].min()} to {df['observation_date'].max()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.2 Time Series Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comprehensive time series plot\n",
                "fig, ax = viz.plot_time_series(\n",
                "    data=df,\n",
                "    date_col='observation_date',\n",
                "    value_col='WPU101704',\n",
                "    title='Producer Price Index - Hot Rolled Steel (1982-2025)',\n",
                "    save_path=FIGURES_DIR / '01_time_series.png'\n",
                ")\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nInitial Visual Observations:\")\n",
                "print(\"- Clear upward trend over the 43-year period\")\n",
                "print(\"- Multiple periods of volatility and price spikes\")\n",
                "print(\"- Possible structural breaks during economic crises\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.3 Trend and Seasonality Decomposition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Additive decomposition\n",
                "print(\"Performing ADDITIVE decomposition...\")\n",
                "decomp_add = viz.plot_decomposition(\n",
                "    data=df,\n",
                "    date_col='observation_date',\n",
                "    value_col='WPU101704',\n",
                "    model='additive',\n",
                "    period=12,\n",
                "    save_path=FIGURES_DIR / '02_decomposition_additive.png'\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Multiplicative decomposition\n",
                "print(\"Performing MULTIPLICATIVE decomposition...\")\n",
                "decomp_mult = viz.plot_decomposition(\n",
                "    data=df,\n",
                "    date_col='observation_date',\n",
                "    value_col='WPU101704',\n",
                "    model='multiplicative',\n",
                "    period=12,\n",
                "    save_path=FIGURES_DIR / '03_decomposition_multiplicative.png'\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze seasonal component\n",
                "print(\"\\nSEASONAL COMPONENT ANALYSIS:\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Extract seasonal component (using additive)\n",
                "seasonal = decomp_add.seasonal.dropna()\n",
                "print(f\"Seasonal component range: {seasonal.min():.2f} to {seasonal.max():.2f}\")\n",
                "print(f\"Seasonal component std dev: {seasonal.std():.2f}\")\n",
                "\n",
                "# Check seasonal strength\n",
                "seasonal_strength = 1 - (decomp_add.resid.var() / (decomp_add.seasonal + decomp_add.resid).var())\n",
                "print(f\"Seasonal strength: {seasonal_strength:.4f}\")\n",
                "\n",
                "if seasonal_strength > 0.6:\n",
                "    print(\"[STRONG] Seasonality detected - consider seasonal models (SARIMA)\")\n",
                "elif seasonal_strength > 0.3:\n",
                "    print(\"[MODERATE] Some seasonality present\")\n",
                "else:\n",
                "    print(\"[WEAK] Minimal seasonality detected\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.4 Stationarity Tests"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Augmented Dickey-Fuller Test\n",
                "def adf_test(series, name=''):\n",
                "    \"\"\"\n",
                "    Perform Augmented Dickey-Fuller test for stationarity\n",
                "    H0: Series has unit root (non-stationary)\n",
                "    H1: Series is stationary\n",
                "    \"\"\"\n",
                "    result = adfuller(series.dropna(), autolag='AIC')\n",
                "    \n",
                "    print(f\"\\nAugmented Dickey-Fuller Test {name}\")\n",
                "    print(\"=\"*60)\n",
                "    print(f\"ADF Statistic: {result[0]:.6f}\")\n",
                "    print(f\"p-value: {result[1]:.6f}\")\n",
                "    print(f\"Number of lags used: {result[2]}\")\n",
                "    print(f\"Number of observations: {result[3]}\")\n",
                "    print(\"\\nCritical Values:\")\n",
                "    for key, value in result[4].items():\n",
                "        print(f\"  {key}: {value:.3f}\")\n",
                "    \n",
                "    if result[1] < 0.05:\n",
                "        print(f\"\\n[STATIONARY] p-value < 0.05: Reject H0, series is stationary\")\n",
                "    else:\n",
                "        print(f\"\\n[NON-STATIONARY] p-value >= 0.05: Fail to reject H0, series is non-stationary\")\n",
                "    \n",
                "    return result\n",
                "\n",
                "# Test original series\n",
                "adf_result = adf_test(df['WPU101704'], '(Original Series)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KPSS Test\n",
                "def kpss_test(series, name=''):\n",
                "    \"\"\"\n",
                "    Perform KPSS test for stationarity\n",
                "    H0: Series is stationary\n",
                "    H1: Series has unit root (non-stationary)\n",
                "    \"\"\"\n",
                "    result = kpss(series.dropna(), regression='ct', nlags='auto')\n",
                "    \n",
                "    print(f\"\\nKPSS Test {name}\")\n",
                "    print(\"=\"*60)\n",
                "    print(f\"KPSS Statistic: {result[0]:.6f}\")\n",
                "    print(f\"p-value: {result[1]:.6f}\")\n",
                "    print(f\"Number of lags used: {result[2]}\")\n",
                "    print(\"\\nCritical Values:\")\n",
                "    for key, value in result[3].items():\n",
                "        print(f\"  {key}: {value:.3f}\")\n",
                "    \n",
                "    if result[1] < 0.05:\n",
                "        print(f\"\\n[NON-STATIONARY] p-value < 0.05: Reject H0, series is non-stationary\")\n",
                "    else:\n",
                "        print(f\"\\n[STATIONARY] p-value >= 0.05: Fail to reject H0, series is stationary\")\n",
                "    \n",
                "    return result\n",
                "\n",
                "# Test original series\n",
                "kpss_result = kpss_test(df['WPU101704'], '(Original Series)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on differenced series\n",
                "df['diff_1'] = df['WPU101704'].diff()\n",
                "\n",
                "print(\"\\n\" + \"#\"*60)\n",
                "print(\"TESTING FIRST DIFFERENCE\")\n",
                "print(\"#\"*60)\n",
                "\n",
                "adf_diff = adf_test(df['diff_1'], '(First Difference)')\n",
                "kpss_diff = kpss_test(df['diff_1'], '(First Difference)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary of stationarity tests\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"STATIONARITY TEST SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(\"\\nOriginal Series:\")\n",
                "print(f\"  ADF Test: {'Stationary' if adf_result[1] < 0.05 else 'Non-Stationary'} (p={adf_result[1]:.4f})\")\n",
                "print(f\"  KPSS Test: {'Stationary' if kpss_result[1] >= 0.05 else 'Non-Stationary'} (p={kpss_result[1]:.4f})\")\n",
                "\n",
                "print(\"\\nFirst Difference:\")\n",
                "print(f\"  ADF Test: {'Stationary' if adf_diff[1] < 0.05 else 'Non-Stationary'} (p={adf_diff[1]:.4f})\")\n",
                "print(f\"  KPSS Test: {'Stationary' if kpss_diff[1] >= 0.05 else 'Non-Stationary'} (p={kpss_diff[1]:.4f})\")\n",
                "\n",
                "print(\"\\nRECOMMENDATION:\")\n",
                "if adf_result[1] >= 0.05 and kpss_result[1] < 0.05:\n",
                "    print(\"  Series is NON-STATIONARY - differencing required for ARIMA (d=1)\")\n",
                "elif adf_result[1] < 0.05 and kpss_result[1] >= 0.05:\n",
                "    print(\"  Series is STATIONARY - no differencing needed (d=0)\")\n",
                "else:\n",
                "    print(\"  Mixed results - recommend differencing for ARIMA (d=1)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.5 Autocorrelation Analysis (ACF/PACF)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ACF and PACF for original series\n",
                "print(\"ACF/PACF for ORIGINAL series:\")\n",
                "viz.plot_acf_pacf(\n",
                "    data=df,\n",
                "    value_col='WPU101704',\n",
                "    lags=40,\n",
                "    save_path=FIGURES_DIR / '04_acf_pacf_original.png'\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ACF and PACF for differenced series\n",
                "print(\"ACF/PACF for DIFFERENCED series:\")\n",
                "viz.plot_acf_pacf(\n",
                "    data=df,\n",
                "    value_col='diff_1',\n",
                "    lags=40,\n",
                "    save_path=FIGURES_DIR / '05_acf_pacf_differenced.png'\n",
                ")\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nARIMA PARAMETER SUGGESTIONS from ACF/PACF:\")\n",
                "print(\"- ACF slowly decaying: suggests AR component\")\n",
                "print(\"- PACF cuts off after lag p: suggests AR(p)\")\n",
                "print(\"- Use auto_arima for optimal parameter selection\")\n",
                "print(\"- Initial guess: ARIMA(1,1,1) or SARIMA(1,1,1)(1,1,1,12)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.6 Distribution Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot distribution\n",
                "viz.plot_distribution(\n",
                "    data=df,\n",
                "    value_col='WPU101704',\n",
                "    save_path=FIGURES_DIR / '06_distribution.png'\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical distribution tests\n",
                "print(\"\\nDISTRIBUTION ANALYSIS:\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Descriptive statistics\n",
                "desc_stats = df['WPU101704'].describe()\n",
                "print(\"\\nDescriptive Statistics:\")\n",
                "for stat, value in desc_stats.items():\n",
                "    print(f\"  {stat}: {value:.2f}\")\n",
                "\n",
                "# Skewness and Kurtosis\n",
                "skewness = df['WPU101704'].skew()\n",
                "kurtosis = df['WPU101704'].kurtosis()\n",
                "\n",
                "print(f\"\\nSkewness: {skewness:.4f}\")\n",
                "if abs(skewness) < 0.5:\n",
                "    print(\"  [SYMMETRIC] Distribution is fairly symmetric\")\n",
                "elif skewness > 0:\n",
                "    print(\"  [RIGHT-SKEWED] Distribution has right tail\")\n",
                "else:\n",
                "    print(\"  [LEFT-SKEWED] Distribution has left tail\")\n",
                "\n",
                "print(f\"\\nKurtosis: {kurtosis:.4f}\")\n",
                "if kurtosis > 3:\n",
                "    print(\"  [LEPTOKURTIC] Heavy tails, more outliers than normal\")\n",
                "elif kurtosis < 3:\n",
                "    print(\"  [PLATYKURTIC] Light tails, fewer outliers than normal\")\n",
                "else:\n",
                "    print(\"  [MESOKURTIC] Normal-like distribution\")\n",
                "\n",
                "# Normality test (Shapiro-Wilk)\n",
                "if len(df) <= 5000:  # Shapiro-Wilk works best for n <= 5000\n",
                "    stat, p_value = stats.shapiro(df['WPU101704'])\n",
                "    print(f\"\\nShapiro-Wilk Test for Normality:\")\n",
                "    print(f\"  Statistic: {stat:.6f}\")\n",
                "    print(f\"  p-value: {p_value:.6f}\")\n",
                "    if p_value < 0.05:\n",
                "        print(\"  [NON-NORMAL] Distribution deviates from normal (p < 0.05)\")\n",
                "    else:\n",
                "        print(\"  [NORMAL] Distribution appears normal (p >= 0.05)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.7 Outlier Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# IQR method for outlier detection\n",
                "Q1 = df['WPU101704'].quantile(0.25)\n",
                "Q3 = df['WPU101704'].quantile(0.75)\n",
                "IQR = Q3 - Q1\n",
                "\n",
                "lower_bound = Q1 - 1.5 * IQR\n",
                "upper_bound = Q3 + 1.5 * IQR\n",
                "\n",
                "outliers = df[(df['WPU101704'] < lower_bound) | (df['WPU101704'] > upper_bound)]\n",
                "\n",
                "print(\"\\nOUTLIER DETECTION (IQR Method):\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Q1 (25th percentile): {Q1:.2f}\")\n",
                "print(f\"Q3 (75th percentile): {Q3:.2f}\")\n",
                "print(f\"IQR: {IQR:.2f}\")\n",
                "print(f\"Lower bound: {lower_bound:.2f}\")\n",
                "print(f\"Upper bound: {upper_bound:.2f}\")\n",
                "print(f\"\\nNumber of outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")\n",
                "\n",
                "if len(outliers) > 0:\n",
                "    print(\"\\nOutlier dates and values:\")\n",
                "    for idx, row in outliers.iterrows():\n",
                "        print(f\"  {row['observation_date'].strftime('%Y-%m')}: {row['WPU101704']:.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Z-score method (additional outlier detection)\n",
                "df['z_score'] = np.abs(stats.zscore(df['WPU101704']))\n",
                "z_outliers = df[df['z_score'] > 3]\n",
                "\n",
                "print(f\"\\nZ-SCORE METHOD (threshold = 3):\")\n",
                "print(f\"Number of outliers: {len(z_outliers)} ({len(z_outliers)/len(df)*100:.2f}%)\")\n",
                "\n",
                "if len(z_outliers) > 0:\n",
                "    print(\"\\nExtreme outliers (|z| > 3):\")\n",
                "    for idx, row in z_outliers.iterrows():\n",
                "        print(f\"  {row['observation_date'].strftime('%Y-%m')}: {row['WPU101704']:.2f} (z={row['z_score']:.2f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.8 Rolling Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot rolling statistics\n",
                "viz.plot_rolling_statistics(\n",
                "    data=df,\n",
                "    date_col='observation_date',\n",
                "    value_col='WPU101704',\n",
                "    windows=[12, 24],\n",
                "    save_path=FIGURES_DIR / '07_rolling_statistics.png'\n",
                ")\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nROLLING STATISTICS ANALYSIS:\")\n",
                "print(\"- 12-month MA smooths out short-term fluctuations\")\n",
                "print(\"- 24-month MA reveals longer-term trends\")\n",
                "print(\"- Rolling std shows periods of high/low volatility\")\n",
                "print(\"- Increasing std suggests heteroscedasticity\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.9 Temporal Patterns: Changes Over Time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot MoM and YoY changes\n",
                "viz.plot_changes(\n",
                "    data=df,\n",
                "    date_col='observation_date',\n",
                "    value_col='WPU101704',\n",
                "    save_path=FIGURES_DIR / '08_mom_yoy_changes.png'\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate and display change statistics\n",
                "df['MoM_pct'] = df['WPU101704'].pct_change() * 100\n",
                "df['YoY_pct'] = df['WPU101704'].pct_change(periods=12) * 100\n",
                "\n",
                "print(\"\\nCHANGE STATISTICS:\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(\"\\nMonth-over-Month % Change:\")\n",
                "print(f\"  Mean: {df['MoM_pct'].mean():.2f}%\")\n",
                "print(f\"  Median: {df['MoM_pct'].median():.2f}%\")\n",
                "print(f\"  Std Dev: {df['MoM_pct'].std():.2f}%\")\n",
                "print(f\"  Min: {df['MoM_pct'].min():.2f}%\")\n",
                "print(f\"  Max: {df['MoM_pct'].max():.2f}%\")\n",
                "\n",
                "print(\"\\nYear-over-Year % Change:\")\n",
                "print(f\"  Mean: {df['YoY_pct'].mean():.2f}%\")\n",
                "print(f\"  Median: {df['YoY_pct'].median():.2f}%\")\n",
                "print(f\"  Std Dev: {df['YoY_pct'].std():.2f}%\")\n",
                "print(f\"  Min: {df['YoY_pct'].min():.2f}%\")\n",
                "print(f\"  Max: {df['YoY_pct'].max():.2f}%\")\n",
                "\n",
                "# Find periods of biggest changes\n",
                "top_increases = df.nlargest(5, 'YoY_pct')[['observation_date', 'WPU101704', 'YoY_pct']]\n",
                "top_decreases = df.nsmallest(5, 'YoY_pct')[['observation_date', 'WPU101704', 'YoY_pct']]\n",
                "\n",
                "print(\"\\nTop 5 YoY Increases:\")\n",
                "for idx, row in top_increases.iterrows():\n",
                "    print(f\"  {row['observation_date'].strftime('%Y-%m')}: +{row['YoY_pct']:.2f}%\")\n",
                "\n",
                "print(\"\\nTop 5 YoY Decreases:\")\n",
                "for idx, row in top_decreases.iterrows():\n",
                "    print(f\"  {row['observation_date'].strftime('%Y-%m')}: {row['YoY_pct']:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.10 Year-over-Year Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot yearly comparison\n",
                "viz.plot_yearly_comparison(\n",
                "    data=df,\n",
                "    date_col='observation_date',\n",
                "    value_col='WPU101704',\n",
                "    save_path=FIGURES_DIR / '09_yearly_comparison.png'\n",
                ")\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nObservations from yearly patterns:\")\n",
                "print(\"- Compare seasonal patterns across recent years\")\n",
                "print(\"- Identify if seasonality is consistent year-over-year\")\n",
                "print(\"- Detect any changing trends in recent periods\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.11 Key Findings Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"KEY FINDINGS - EDA (STEP 2)\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(\"\\n1. TREND:\")\n",
                "print(\"   - Strong upward trend over 43 years\")\n",
                "print(\"   - Multiple structural breaks during economic events\")\n",
                "print(\"   - Recent values near historical highs\")\n",
                "\n",
                "print(\"\\n2. SEASONALITY:\")\n",
                "seasonal_strength = 1 - (decomp_add.resid.var() / (decomp_add.seasonal + decomp_add.resid).var())\n",
                "print(f\"   - Seasonal strength: {seasonal_strength:.4f}\")\n",
                "if seasonal_strength > 0.3:\n",
                "    print(\"   - [PRESENT] Seasonal patterns detected\")\n",
                "    print(\"   - Recommend SARIMA over ARIMA\")\n",
                "else:\n",
                "    print(\"   - [WEAK] Minimal seasonal patterns\")\n",
                "\n",
                "print(\"\\n3. STATIONARITY:\")\n",
                "print(f\"   - ADF test p-value: {adf_result[1]:.4f}\")\n",
                "print(f\"   - KPSS test p-value: {kpss_result[1]:.4f}\")\n",
                "if adf_result[1] >= 0.05:\n",
                "    print(\"   - [NON-STATIONARY] Series requires differencing\")\n",
                "    print(\"   - Recommendation: d=1 for ARIMA\")\n",
                "else:\n",
                "    print(\"   - [STATIONARY] No differencing needed\")\n",
                "\n",
                "print(\"\\n4. DISTRIBUTION:\")\n",
                "print(f\"   - Skewness: {skewness:.4f} ({'Right-skewed' if skewness > 0 else 'Left-skewed'})\")\n",
                "print(f\"   - Kurtosis: {kurtosis:.4f}\")\n",
                "print(f\"   - Shape: Non-normal distribution\")\n",
                "\n",
                "print(\"\\n5. OUTLIERS:\")\n",
                "print(f\"   - IQR method: {len(outliers)} outliers ({len(outliers)/len(df)*100:.2f}%)\")\n",
                "print(f\"   - Z-score method: {len(z_outliers)} extreme outliers\")\n",
                "if len(outliers) > 0:\n",
                "    print(\"   - Most outliers during economic crises/commodity booms\")\n",
                "\n",
                "print(\"\\n6. VOLATILITY:\")\n",
                "recent_std = df['WPU101704'].tail(60).std()\n",
                "overall_std = df['WPU101704'].std()\n",
                "print(f\"   - Overall std: {overall_std:.2f}\")\n",
                "print(f\"   - Recent std (5y): {recent_std:.2f}\")\n",
                "print(f\"   - CV: {(overall_std/df['WPU101704'].mean())*100:.2f}%\")\n",
                "\n",
                "print(\"\\n7. AUTOCORRELATION:\")\n",
                "print(\"   - High autocorrelation in ACF (slowly decaying)\")\n",
                "print(\"   - PACF suggests AR component\")\n",
                "print(\"   - Suitable for ARIMA modeling\")\n",
                "\n",
                "print(\"\\n8. MODEL RECOMMENDATIONS:\")\n",
                "print(\"   - Baseline: Holt-Winters (captures trend + seasonality)\")\n",
                "if seasonal_strength > 0.3:\n",
                "    print(\"   - SARIMA: Recommended due to seasonality\")\n",
                "    print(\"   - Initial params: SARIMA(1,1,1)(1,1,1,12)\")\n",
                "else:\n",
                "    print(\"   - ARIMA: Start with ARIMA(1,1,1)\")\n",
                "print(\"   - Prophet: Good for capturing multiple seasonalities\")\n",
                "print(\"   - LSTM: Worth trying due to complex patterns\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"[OK] STEP 2: EDA - COMPLETED SUCCESSFULLY\")\n",
                "print(\"=\"*70)\n",
                "print(\"\\nNext Step: Data Preprocessing (Step 3)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.12 Save Summary Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create summary dictionary\n",
                "eda_summary = {\n",
                "    'observations': len(df),\n",
                "    'date_range': f\"{df['observation_date'].min()} to {df['observation_date'].max()}\",\n",
                "    'trend': 'Upward',\n",
                "    'seasonal_strength': float(seasonal_strength),\n",
                "    'stationarity': {\n",
                "        'adf_pvalue': float(adf_result[1]),\n",
                "        'kpss_pvalue': float(kpss_result[1]),\n",
                "        'is_stationary': bool(adf_result[1] < 0.05)\n",
                "    },\n",
                "    'distribution': {\n",
                "        'skewness': float(skewness),\n",
                "        'kurtosis': float(kurtosis),\n",
                "        'is_normal': False\n",
                "    },\n",
                "    'outliers': {\n",
                "        'iqr_count': len(outliers),\n",
                "        'zscore_count': len(z_outliers)\n",
                "    },\n",
                "    'volatility': {\n",
                "        'overall_std': float(overall_std),\n",
                "        'cv_percent': float((overall_std/df['WPU101704'].mean())*100)\n",
                "    },\n",
                "    'figures_saved': [\n",
                "        '01_time_series.png',\n",
                "        '02_decomposition_additive.png',\n",
                "        '03_decomposition_multiplicative.png',\n",
                "        '04_acf_pacf_original.png',\n",
                "        '05_acf_pacf_differenced.png',\n",
                "        '06_distribution.png',\n",
                "        '07_rolling_statistics.png',\n",
                "        '08_mom_yoy_changes.png',\n",
                "        '09_yearly_comparison.png'\n",
                "    ]\n",
                "}\n",
                "\n",
                "# Save to JSON\n",
                "import json\n",
                "summary_path = project_root / 'results' / 'eda_summary.json'\n",
                "with open(summary_path, 'w') as f:\n",
                "    json.dump(eda_summary, f, indent=4, default=str)\n",
                "\n",
                "print(f\"\\n[OK] EDA summary saved to: {summary_path}\")\n",
                "print(f\"[OK] {len(eda_summary['figures_saved'])} figures saved to: {FIGURES_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Summary\n",
                "\n",
                "**Step 2: Exploratory Data Analysis - COMPLETE ✓**\n",
                "\n",
                "We have successfully:\n",
                "- ✓ Visualized time series patterns\n",
                "- ✓ Decomposed trend and seasonal components\n",
                "- ✓ Tested for stationarity (ADF, KPSS)\n",
                "- ✓ Analyzed autocorrelation (ACF/PACF)\n",
                "- ✓ Examined distribution and detected outliers\n",
                "- ✓ Analyzed temporal patterns (MoM, YoY)\n",
                "- ✓ Calculated rolling statistics\n",
                "- ✓ Saved 9 analysis figures\n",
                "\n",
                "**Key Insights:**\n",
                "- Non-stationary series requiring differencing (d=1)\n",
                "- Seasonal patterns detected (consider SARIMA)\n",
                "- Complex volatility patterns (LSTM may help)\n",
                "- Ready for preprocessing and modeling\n",
                "\n",
                "**Ready for Step 3: Data Preprocessing**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}